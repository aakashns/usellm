---
title: llmService.voiceChat
description: Performs a voice chat conversation with the OpenAI model
---

`llmService.voiceChat()` is a server-side function in the useLLM framework that performs a voice chat conversation with the OpenAI model. It transcribes the audio, generates chat messages, and retrieves the response audio.

### Syntax:

```typescript
const result = await llmService.voiceChat({
  transcribeAudioUrl: string,
  transcribeLanguage?: string,
  transcribePrompt?: string,
  chatMessages?: OpenAIMessage[],
  chatTemplate?: string,
  chatInputs?: object,
  voice: object,
  audioConfig: object,
});
```

### Parameters:

`llmService.voiceChat()` accepts an object of type LLMServiceVoiceChatOptions with the following properties:

- **transcribeAudioUrl** (required): A string representing the URL of the audio file to be transcribed.
- **transcribeLanguage** (optional): A string indicating the language of the audio for transcription.
- **transcribePrompt** (optional): A string representing the prompt to be used during transcription.
- **chatMessages** (optional): An array of `OpenAIMessage` objects representing the chat messages. Additional chat messages can be included along with the transcribed text.
- **chatTemplate** (optional): The name of the template to be used for the chat.
- **chatInputs** (optional): Additional inputs to be passed along with the chat request.
- **voice** (required): An object specifying the voice settings for the TTS operation. It includes the following properties:
  - languageCode (required): The language code of the voice e.g. en-US.
  - name (optional): The name of the voice.
  - ssmlGender (optional): The SSML gender of the voice.
  - customVoice (optional): An object specifying a custom voice model and its reported usage.
- **audioConfig** (required): An object specifying the audio configuration for the TTS operation. It includes the following properties:
  - audioEncoding (required): The audio encoding format (e.g., "LINEAR16", "MP3", "OGG_OPUS", "MULAW", "ALAW").
  - speakingRate (optional): The speaking rate.
  - pitch (optional): The pitch of the voice.
  - volumeGainDb (optional): The volume gain in decibels.
  - sampleRateHertz (optional): The sample rate in hertz.
  - effectsProfileId (optional): An array of effects profile IDs.

### Returns:

This method returns a Promise that resolves to an object with the following properties:

- **audioUrl**: A string representing the base64 encoded data of the generated speech audio.
- **messages**: An array of `OpenAIMessage` objects representing the chat messages, including the user input and the assistant's response.

### Error Handling:

`llmService.voiceChat()` may throw an error if:

- The `transcribeAudioUrl` parameter is missing or invalid.
- The `voice` parameter is missing or invalid.
- The `audioConfig` parameter is missing or invalid.
- An error occurs during the transcription, chat, or speech synthesis processes.

### Example

Below is an example of how to use `llmService.voiceChat()` within a server-side API route:

```typescript
/* pages/api/llm.ts */

import { createLLMService } from "usellm";

export const config = {
  runtime: "edge",
};

const llmService = createLLMService({
  openaiApiKey: process.env.OPENAI_API_KEY,
  googleClientID: preocess.env.GOOGLE_CLIENT_ID,
  googleClientSecret: process.env.GOOGLE_CLIENT_SECRET,
  googleRefreshToken: process.env.GOOGLE_REFRESH_TOKEN,
  actions: ["chat", "transcribe", "embed", "speak"],
});

export default async function handler(request: Request) {
  const body = await request.json();
  console.log(body);

  try {
    const result = await llmService.voiceChat(body);
    console.log(result);
    return new Response(JSON.stringify(result), { status: 200 });
  } catch (error: any) {
    return new Response(error.message, { status: error?.status || 400 });
  }
}

```

In this example, the `llmService.voiceChat()` method is used to perform a voice chat conversation with the LLM service. It transcribes the audio, generates chat messages, and retrieves the response audio. The options object is passed to the `llmService.voiceChat()` method call. You can modify the options based on your requirements, including the audio URL, language, prompt, chat messages, templates, and speech synthesis settings. The response, including the generated speech audio URL and chat messages, is returned as the result. If an error occurs, an appropriate error response is returned.